{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "XF5ZysGhELAN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim"
      ],
      "metadata": {
        "id": "3drq5ay5EBUL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0daa0732-4514-4ccf-b036-adcde946cbd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --force-reinstall numpy\n",
        "!pip install --upgrade --force-reinstall gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RYOA8SaAWHsd",
        "outputId": "f7f00b88-1c7f-428c-ea17-94461e087b8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy\n",
            "  Using cached numpy-2.2.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "Using cached numpy-2.2.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.2.4 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.4 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.2.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-2.2.4\n",
            "Collecting gensim\n",
            "  Using cached gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
            "Collecting numpy<2.0,>=1.18.5 (from gensim)\n",
            "  Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Collecting scipy<1.14.0,>=1.7.0 (from gensim)\n",
            "  Using cached scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "Collecting smart-open>=1.8.1 (from gensim)\n",
            "  Using cached smart_open-7.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting wrapt (from smart-open>=1.8.1->gensim)\n",
            "  Using cached wrapt-1.17.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
            "Using cached gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n",
            "Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "Using cached scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
            "Using cached smart_open-7.1.0-py3-none-any.whl (61 kB)\n",
            "Using cached wrapt-1.17.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (83 kB)\n",
            "Installing collected packages: wrapt, numpy, smart-open, scipy, gensim\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.17.2\n",
            "    Uninstalling wrapt-1.17.2:\n",
            "      Successfully uninstalled wrapt-1.17.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.2.4\n",
            "    Uninstalling numpy-2.2.4:\n",
            "      Successfully uninstalled numpy-2.2.4\n",
            "  Attempting uninstall: smart-open\n",
            "    Found existing installation: smart-open 7.1.0\n",
            "    Uninstalling smart-open-7.1.0:\n",
            "      Successfully uninstalled smart-open-7.1.0\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.13.1\n",
            "    Uninstalling scipy-1.13.1:\n",
            "      Successfully uninstalled scipy-1.13.1\n",
            "  Attempting uninstall: gensim\n",
            "    Found existing installation: gensim 4.3.3\n",
            "    Uninstalling gensim-4.3.3:\n",
            "      Successfully uninstalled gensim-4.3.3\n",
            "Successfully installed gensim-4.3.3 numpy-1.26.4 scipy-1.13.1 smart-open-7.1.0 wrapt-1.17.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "import os"
      ],
      "metadata": {
        "id": "mcxfa5QVV746"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import files\n",
        "\n",
        "# uploaded = files.upload()  # This will open a file upload dialog"
      ],
      "metadata": {
        "id": "NTA_vtszV-ER"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')\n",
        "import os\n",
        "from nltk import sent_tokenize\n",
        "from gensim.utils import simple_preprocess\n",
        "\n",
        "# List of uploaded files\n",
        "file_list = [\"001ssb.txt\", \"002ssb.txt\", \"003ssb.txt\", \"004ssb.txt\", \"005ssb.txt\"]\n",
        "\n",
        "story = []\n",
        "\n",
        "for filename in file_list:\n",
        "    # Try reading with 'latin-1' encoding first\n",
        "    try:\n",
        "        with open(filename, \"r\", encoding=\"latin-1\") as f:\n",
        "            corpus = f.read()  # Read file content\n",
        "    except UnicodeDecodeError:\n",
        "        # If 'latin-1' fails, try 'cp1252'\n",
        "        try:\n",
        "            with open(filename, \"r\", encoding=\"cp1252\") as f:\n",
        "                corpus = f.read()\n",
        "        except UnicodeDecodeError:\n",
        "            # If both fail, print an error and skip the file\n",
        "            print(f\"Error: Could not decode file {filename}. Skipping...\")\n",
        "            continue\n",
        "\n",
        "    raw_sent = sent_tokenize(corpus)  # Sentence tokenization\n",
        "    for sent in raw_sent:\n",
        "        story.append(simple_preprocess(sent))  # Preprocess text\n",
        "\n",
        "# Check processed output\n",
        "print(story[:5])  # Print first 5 processed sentences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BjC8_YQYXERS",
        "outputId": "a96bde5e-9c4f-4c2f-fa10-06e2b4c94191"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['game', 'of', 'thrones', 'book', 'one', 'of', 'song', 'of', 'ice', 'and', 'fire', 'by', 'george', 'martin', 'prologue', 'we', 'should', 'start', 'back', 'gared', 'urged', 'as', 'the', 'woods', 'began', 'to', 'grow', 'dark', 'around', 'them'], ['the', 'wildlings', 'are', 'dead'], ['do', 'the', 'dead', 'frighten', 'you'], ['ser', 'waymar', 'royce', 'asked', 'with', 'just', 'the', 'hint', 'of', 'smile'], ['gared', 'did', 'not', 'rise', 'to', 'the', 'bait']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(story)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5FubrqYXJKx",
        "outputId": "eb3c72b6-24c2-4f92-caf3-f96d20f568a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "145020"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "model = Word2Vec(story, window=10, min_count=2)"
      ],
      "metadata": {
        "id": "r6-Qqb2BXsW6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.build_vocab(story)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55VoXbU6Xznp",
        "outputId": "43152436-f6c2-4a54-c976-ff8f6b58eda3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.keyedvectors:sorting after vectors have been allocated is expensive & error-prone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.train(story, total_examples=model.corpus_count, epochs=model.epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHaO0fkqYLux",
        "outputId": "40ca2611-2774-4852-c3b8-6f3e2b062ba5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.word2vec:Effective 'alpha' higher than previous training cycles\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6570553, 8628190)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.wv.most_similar(\"jon\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TD9XjhwEYTQx",
        "outputId": "134552e0-b47a-4fb5-85e6-0d87be064da4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('sam', 0.6035617589950562),\n",
              " ('tormund', 0.5924491286277771),\n",
              " ('pyp', 0.576863706111908),\n",
              " ('bran', 0.5709148645401001),\n",
              " ('qhorin', 0.5418316721916199),\n",
              " ('grenn', 0.5389629602432251),\n",
              " ('ygritte', 0.5283386707305908),\n",
              " ('halfhand', 0.5204776525497437),\n",
              " ('theon', 0.5134130120277405),\n",
              " ('ned', 0.5111159086227417)]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.wv.distance(\"jon\", \"arya\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzH24YnbYeYJ",
        "outputId": "575a99db-c399-437d-ebd8-06a6b527fe29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6209160089492798"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.wv.doesnt_match([\"jon\", \"arya\", \"ned\", \"catelay\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "DhhaTCi1YmBp",
        "outputId": "0398fdd5-f585-48b7-d252-303a6464ec56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.keyedvectors:vectors for words {'catelay'} are not present in the model, ignoring these words\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'jon'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.wv[\"jon\"] + model.wv[\"arya\"] - model.wv[\"ned\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXLjcO2mYqP5",
        "outputId": "85e0e5f0-e885-457e-a1c1-715ff91e207a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.14024687,  2.5891385 , -4.2608128 , -0.04774666, -1.135166  ,\n",
              "        3.828346  ,  2.1678982 , -1.3786976 , -0.87021625, -0.07624924,\n",
              "        4.5627    , -3.3338614 , -0.81320155, -1.1230565 , -0.60434556,\n",
              "        0.65657777,  1.7216144 ,  3.1955    , -1.6521795 , -1.9350547 ,\n",
              "       -1.6653895 ,  2.2636762 ,  2.1655273 , -2.9893012 , -2.5879383 ,\n",
              "        0.55771315,  1.8510363 , -0.94131637, -4.0910373 , -2.4970531 ,\n",
              "        0.22815776,  2.6196237 ,  2.4253092 , -2.210961  , -0.5565731 ,\n",
              "        3.5849342 , -2.7138028 , -0.06681889, -0.595286  ,  0.5696061 ,\n",
              "       -0.00632399, -0.23212086,  1.2641073 , -3.8058214 , -2.6553624 ,\n",
              "       -0.31259626, -0.78398424, -1.7895856 , -0.5217656 , -1.1889412 ,\n",
              "       -1.3138416 ,  0.05507648, -2.901109  ,  0.9677055 ,  3.009379  ,\n",
              "       -1.1662353 , -0.54726654,  0.57850623, -0.8048432 , -1.6522421 ,\n",
              "        1.2901533 , -2.2822165 , -1.433604  ,  1.0130198 ,  0.6679319 ,\n",
              "       -0.25355253, -1.7632363 ,  0.06230481,  0.13491847,  0.12229818,\n",
              "       -2.625689  ,  2.3149648 , -0.32274908,  0.10998011, -0.6490378 ,\n",
              "        1.0920105 ,  3.1935391 ,  1.139614  , -1.0563562 , -3.1206503 ,\n",
              "        0.15104043, -1.5706099 ,  2.3070617 ,  0.640882  ,  0.25151563,\n",
              "       -0.16636944,  0.83582914, -0.4696517 ,  0.03558052,  3.9425952 ,\n",
              "       -1.3230302 , -0.03142196, -0.06547999, -0.30582023,  3.503765  ,\n",
              "        0.24591732,  1.5885088 ,  0.49199387,  1.7207566 ,  0.4322235 ],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.wv.similarity(\"arya\", \"ned\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rsPOc1xxYz5x",
        "outputId": "30e76851-a0d8-4d27-cabb-5a3783e1d0a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.59578305"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uHhLMDQjY6Lq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}